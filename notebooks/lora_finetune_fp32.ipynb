{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Fine-tune Gemma 2 with LoRA (FP32 Precision)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook shows how to fine-tune the Gemma 2 (2B) model using the LoRA (Low-Rank Adaptation) technique, using standard FP32 precision.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Environment Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages\\n\",\n",
    "    \"!pip install -q -U wandb keras-nlp \\\"keras>=3\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import the required modules\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import wandb\\n\",\n",
    "    \"import random\\n\",\n",
    "    \"import math\\n\",\n",
    "    \"import keras\\n\",\n",
    "    \"import keras_nlp\\n\",\n",
    "    \"import gc\\n\",\n",
    "    \"from keras.callbacks import EarlyStopping\\n\",\n",
    "    \"from wandb.integration.keras import WandbMetricsLogger\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# log in Weights & Biases\\n\",\n",
    "    \"wandb.login()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Selecting a backend\\n\",\n",
    "    \"\\n\",\n",
    "    \"Keras is a high-level, multi-framework deep learning API designed to be simple and easy to use. With Keras 3, you can run your workflows on one of three backends: TensorFlow, JAX, or PyTorch.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "       \"os.environ[\\\"KERAS_BACKEND\\\"] = \\\"jax\\\" \n",
    "       # or \\\"torch\\\" or \\\"tensorflow\\\".\\n# Avoid memory fragmentation on the JAX backend.\\nos.environ[\\\"XLA_PYTHON_CLIENT_MEM_FRACTION\\\"]=\\\"1.00\\\"\\n\\n# Make sure the GPU is available\\n!nvidia-smi\\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
